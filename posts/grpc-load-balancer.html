<html>

<head>
  <title>gRPC Load balancing (1) | Linh tinh</title>
  <meta charset="utf-8">
  <meta http-equiv="content-type" content="text/html;">
  <meta name=viewport content="initial-scale=1.0 maximum-scale=1.0">
  <meta property='og:image' content='https://melancholy.com/img/default.jpg'>
  <link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
  <link rel="manifest" href="../manifest.json">
  <link rel="mask-icon" href="../safari-pinned-tab.svg" color="#5bbad5">
  <meta name="theme-color" content="#ffffff">
  <link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin-ext,vietnamese"
    rel="stylesheet">
  <!-- <link href="../css/theme.css?t=" rel="stylesheet" type="text/css"> -->
  <link href="/css/theme.css" rel="stylesheet" type="text/css">
  <!-- <link href="/css/gruvbox-dark.css" rel="stylesheet" type="text/css"> -->
  <link rel="stylesheet" href="../css/highlight/tomorrow.css">
  <link rel="stylesheet" href="../css/fontello.css">
  <link rel="stylesheet" href="../emoji/css/emoji.dist.css">
  <link rel="stylesheet" href="../emoji/css/emojione.min.css">
  <link rel="stylesheet" href="../emoji/css/messenger.min.css">
  <link rel="stylesheet" href="../emoji/css/thinking.ext.css">
  <!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/default.min.css"> -->
  <script src="../js/highlight.min.js"></script>
  <script src="../js/autosizing.js"></script>
  <script src="../js/fetch.js"></script>
  <script>
    hljs.initHighlightingOnLoad();
    hljs.highlightAll();
  </script>
</head>

<body>
  <div class="header">
    <a href="/"><span class="avatar"></span><span class="header-link">Linh tinh</span></a>
  </div>
  <div class="container">
    <div class="main">
      <p><a href="/">&lt;- Quay về trang chủ</a></p>
      <h1>gRPC Load balancing (1)</h1>
      <p>Khi thị trường có xu hướng chuyển dần từ monolithic sang microservice, bài toán giao tiếp giữa các service trở nên rất quan trọng, với những service thông thường hiện nay, mình thấy có 3 cách giao tiếp phổ biến:</p>
<ul>
<li><code>REST APIs</code></li>
<li><code>gRPC</code></li>
<li><code>Message queue</code></li>
</ul>
<p>Khi triển khai hệ thống cần xử lý một lượng tải lớn, mỗi loại service sẽ cần phải chạy rất nhiều instance, vậy bài toán đặt ra làm thế nào để chia tải giữa các instance? Độ hiệu quả cũng như chi phí cài đặt, bảo trì như thế nào? Phương pháp áp dụng cho mỗi protocol có khác nhau không?</p>
<p>Để trả lời những câu hỏi trên, mình sẽ viết một chuỗi bài tìm hiểu về cân bằng tải gRPC và các phương pháp hiện thực trong thực tế. Thông qua chuỗi bài viết này, mục tiêu được đặt ra là mình và bạn đọc sẽ hiểu rõ và vận dụng được những kiến thức cân bằng tải gRPC dự án thực tế, cụ thể:</p>
<ul>
<li>Hiểu lý thuyết cân bằng tải.</li>
<li>Hiểu phương pháp cân bằng tải ở <code>transport layer</code> và <code>application layer</code>.</li>
<li>Thiết lập và kiểm thử các phương pháp cân bằng tải gRPC.</li>
</ul>
<h2><a href="#phương-pháp" aria-hidden="true" class="anchor" id="phương-pháp"></a>Phương pháp</h2>
<p>Hiện tại có một vài phương pháp phổ biến để xử lý cân bằng tải cho grPC:</p>
<ul>
<li><strong>Proxy load balancing</strong>: là phương pháp truyền thống, LB sẽ đóng vai trò như một reverse proxy, HAProxy, Nginx, LB của cloud provider,... là các ví dụ.</li>
<li><strong>Client side load balancing</strong>: phía client chủ động quản lý connection cũng như cơ chế load balancing, có thể tự custom hoàn toàn dựa trên các specification của gRPC hoặc kết hợp với ZooKeeper/Etcd/Consul,...</li>
<li><strong>Look-aside load balancing</strong>: có một external load balancing component chịu trách nhiệm quản lý các servers (service discovery) và trả lời thông tin cho client mỗi khi được yêu cầu.</li>
<li><strong>Service mesh</strong>: chịu trách nhiệm hiện thực service discovery và cân bằng tải: <code>Istio + Envoy proxy</code>,...</li>
</ul>
<p>Mỗi phương pháp sẽ có ưu nhược điểm riêng cũng như chi phí cài đặt, bảo trì khác nhau.</p>
<p>Tuy nhiên, trước hết hãy cùng mình tìm hiểu một số kiến thức cơ bản cần nắm rõ như <code>HTTP/2</code>, <code>long-lived TCP connection</code>,...</p>
<h3><a href="#http2" aria-hidden="true" class="anchor" id="http2"></a>HTTP/2</h3>
<p><code>HTTP/2</code> cho phép client và server gửi/nhận cùng lúc nhiều request/response trên cùng 1 TCP connection (<code>multiplexing</code>), phân biệt với nhau dựa trên <code>logical stream</code>.</p>
<p><img src="img/http2.png" alt="http/2" /></p>
<p><code>HTTP/2</code> ra đời giản quyết vấn đề <a href="https://en.wikipedia.org/wiki/Head-of-line_blocking">head-of-line_blocking</a> của <code>HTTP/1.1</code>, ở phiên bản cũ, mặc dù chúng ta có thể tái sử dụng connection, nhưng những requests được xử lý tuần tự, có thể gây hiện tượng thắt cổ chai nếu có nhiều request trên cùng 1 connection.</p>
<p>Với tính chất này, nếu không có yêu cầu gì đặc biệt, chúng ta sẽ có nhu cầu tái sử dụng connection của <code>HTTP/2</code> để giảm thiểu chi phí khởi tạo connection, do đó, <code>TCP connection</code> trong <code>HTTP/2</code> sẽ là <code>long-lived connection</code>.</p>
<h2><a href="#grpc-load-balancing" aria-hidden="true" class="anchor" id="grpc-load-balancing"></a>gRPC load balancing</h2>
<h3><a href="#load-balancer-as-proxy" aria-hidden="true" class="anchor" id="load-balancer-as-proxy"></a>Load balancer as proxy</h3>
<p><em><strong>Transport layer (layer 4)</strong></em></p>
<p>Khi cân bằng tải ở tầng <code>transport</code>, LB sẽ làm việc với các gói tin TCP, một khi client khởi tạo connection tới LB, nó sẽ tạo 1 connection tương ứng đến một backend server rồi chuyển tiếp tất cả gói tin dựa trên sự ánh xạ này, sự ánh xạ này sẽ được giữ cho đến khi connection bị đóng, từ tổng thể, 2 connection được tạo ra có thể được xem là 1 <code>persistent connection</code>.</p>
<p><img src="img/grpc-connection-load-balancing.png" alt="grpc-connection-load-balancing" /></p>
<p>Do tính chất <code>persistent connection</code>, LB sẽ cân bằng tải cho quá trình thiết lập connection, một khi connection đã được tạo, tất cả request sẽ được gửi thông nó, mình gọi nó là <code>connection-based load balancing</code>. Ở ví dụ như hình trên, nếu client chỉ tạo 1 connection thì sẽ gây ra hiện tượng <code>server instance 2</code> hoặc <code>server instance 3</code> ở trạng thái <code>&quot;thư giãn&quot;</code>.</p>
<!-- Tuy nhiên, vấn đề xuất hiện vì tính chất `long-lived` này, khi LB tạo connection tới một backend server, tất cả những requests sau đó sẽ được gửi đến `server instance 1`, 2 servers còn lại sẽ ngồi chơi. Khi tạo mới một connection khác, tuỳ vào thuật toán `load balancing` ở LB, connection mới có thể sẽ tới `server instance 2` hoặc `server instance 3`. Vậy bạn có thể thấy, dù cho LB load balance ở `layer 4` hay `layer 7` thì kiểu load balancing này là `connection-based load balancing`. -->
<p>Để giải quyết vấn đề này, chúng ta sẽ sử dụng kĩ thuật <code>pooling</code> ở phía client, mục đích là tạo nhiều connections thông qua LB và sử dụng chúng để gửi request. Khi pool được tạo:</p>
<ul>
<li>Tất cả connections sẽ được LB phân tải dựa trên thuật toán đã được cấu hình.</li>
<li>Client sẽ thực hiện chia tải <strong>từng request</strong> trên <strong>từng connection</strong> ở trong pool.</li>
</ul>
<p>Tuy nhiên, chi phí để hiện thực ở phía client sẽ cao hơn vì các lý do:</p>
<ul>
<li>Quản lý pool</li>
<li>Cân bằng tải requests dựa vào connection ở trong pool.</li>
<li>Phụ thuộc vào ngôn ngữ lập trình được sử dụng.</li>
</ul>
<p><img src="img/grpc-loadbalacning-lb-proxy.png" alt="grpc-loadbalacning-lb-proxy" /></p>
<p><em><strong>Điều gì sẽ xảy ra khi scale server?</strong></em></p>
<p>Khi một server mới được thêm vào cụm backend, nếu pool ở client của chúng ta đã đạt đến số connection tối đa thì cách làm này gặp vấn đề lớn, sẽ không có connection mới nào được khởi tạo đến server mới và dẫn đến sự quá tải ở các server đang có, dẫn đến sập server nếu số lượng request tăng. Để giải quyết vấn đề này, chúng ta cần có cơ chế refresh pool, mỗi connection trong pool sẽ có 1 thời gian sống nhất định, client sẽ chạy 1 job để refresh pool theo cơ chế như:</p>
<ul>
<li>Đóng những connection đã hết thời gian sống.</li>
<li>Đóng những connection bị lỗi.</li>
<li>Khởi tạo connection mới thông qua LB.</li>
</ul>
<p>Điều này đảm bảo connection sẽ được chia tải đều đến các server, tuy nhiên chúng ta cần tính toán kĩ những số liệu trên dựa trên đặc điểm chịu tải của từng service, việc này có thể được làm thông qua quá trình <code>benchmark</code> hệ thống.</p>
<!-- ### Layer 7 -->
<p><em><strong>Application layer (layer 7)</strong></em></p>
<p>Khi LB hoạt động ở tầng <code>application</code>, nó sẽ sử dụng các thông tin về request để cân bằng tải, cũng với ví dụ client tạo 1 connection tới LB như ở trên rồi gửi requests, lúc này LB sẽ cân bằng tải từng request một tới các backend server dựa trên các thuật toán được cấu hình.</p>
<p><img src="img/grpc-loadbalacning-L7.png" alt="/grpc-loadbalacning-L7" /></p>
<p>Ở tầng <code>application</code>, LB sử dụng được nhiều thông tin hơn để cân bằng tải, do đó có thể hỗ trợ các thuật toán cân bằng tải phức tạp. Tuy nhiên, vì cần phải xem nội dung của request, hiệu năng lúc này sẽ giảm xuống so với trường hợp LB hoạt động ở tầng <code>transport</code>.</p>
<p><em><strong>Không sử dụng load balancer?</strong></em></p>
<p>Đối với những hệ thống yêu cầu khắt khe về hiệu năng, sử dụng load balancer có lẽ không phải là giải pháp tốt. Client có một lợi thế khi sử dụng <code>load balancer</code> là nó không cần phải quan tâm đến địa chỉ IP cụ thể của backend hay những thứ khác liên quan đến hạ tầng, tất cả những thứ nó cần phải biết là địa chỉ của load balancer, nếu chúng ta không sử dụng load balancer, một vấn đề mới xuất hiện, <strong>làm thế nào để client và server tìm thấy nhau?</strong></p>
<p>Đây là câu hỏi kinh điển gắn liền với thuật ngữ <code>service discovery</code>, có một service thứ 3 đứng ra làm cầu nối giữa client và server, service này lưu thông tin của server và trả lời mỗi khi client hỏi hoặc chủ động thông báo mỗi khi có sự thay đổi. Khi client có được địa chỉ của các server thông qua service thứ 3 này, nó sẽ khởi tạo connection trực tiếp đến các server và <strong>chia tải request</strong> trên các connection này, việc load balancing đã trở thành <code>client-side load balacing</code>, <code>gRPC client</code> đang đảm nhiệm việc cân bằng tải, khi mình nói đến <code>gRPC client</code>, tức là việc xử lý này sẽ được xử lý bởi <code>gRPC</code>, lập trình viên không cần hiện thực thêm gì.</p>
<p><img src="img/grpc-service-discovery.png" alt="grpc-service-discovery" /></p>
<p>Ý tưởng này có thể được hiện thực thông qua nhiều mô hình:</p>
<ul>
<li>Service mesh by <code>Istio + Envoy proxy</code>:
<ul>
<li>control plane: <code>service discovery</code>, cấu hình load balancing policy.</li>
<li>data plance: Envoy proxy cân bằng tải dựa trên các thông tin được cấu hình ở <code>control plance</code>.</li>
</ul>
</li>
<li><a href="https://github.com/grpc/proposal/blob/master/A27-xds-global-load-balancing.md">xDS API</a>: <code>look-aside</code> load balancing, <code>gRPC client</code> hỗ trợ việc sử dụng xDS API của Envoy thông qua <code>resolver</code> và <code>LB plugin</code>, <code>resolver</code> và <code>LB plugin</code> sẽ cần tương tác với một <code>xDS server</code>.</li>
</ul>
<p>Để tăng hiệu năng cũng như throughput về mặt số lượng request, chúng ta cũng có thể áp dụng kĩ thuật pooling ở phía client cho phương pháp này.</p>
<h2><a href="#tổng-kết" aria-hidden="true" class="anchor" id="tổng-kết"></a>Tổng kết</h2>
<p>Ở bài viết này, mình đã phân tích ý tưởng load balancing grpc, có 2 điều cần hiểu rõ để tránh mơ hồ trong lúc hiện thực các phương pháp này:</p>
<ul>
<li><code>connection-based load balancing:</code> chia tải từng connection đến từng backend server, những connection này có tính chất <code>long-lived</code>.</li>
<li><code>request-based load balancing:</code> chia tải từng request đến từng connection, có thể hiểu chia tải ở tầng ứng dụng.</li>
</ul>
<p>Ở các bài tiếp theo, mình sẽ đi vào hiện thực và kiểm thử các phương pháp cân bằng tải gRPC để làm rõ hơn phần lý thuyết này.</p>
<h2><a href="#tham-khảo" aria-hidden="true" class="anchor" id="tham-khảo"></a>Tham khảo</h2>
<ul>
<li><a href="https://grpc.io/blog/grpc-load-balancing/">gRPC Load Balancing</a></li>
<li><a href="https://phuc-ch.medium.com/exploring-grpc-load-balancing-gateway-service-mesh-and-xds-with-go-a527ab0e7ce8">Exploring gRPC Load Balancing: Gateway, Service Mesh, and xDS with Go</a></li>
<li><a href="https://arpittech.medium.com/grpc-and-connection-pooling-49a4137095e7">GRPC and Connection Pooling</a></li>
</ul>

      <div class='other-tags'><b>Tags:</b> <a class='topic-tag' href='/tags/networking.html'>networking</a><a class='topic-tag' href='/tags/gRPC.html'>gRPC</a></div>
      <!-- <div class="copyright">
                Bạn được toàn quyền chia sẻ, trích dẫn hoặc copy, post lại, nhưng vui lòng ghi rõ nguồn, tác giả và không làm thay đổi nội dung bài viết. Nếu không làm vậy, thì OK, cũng ko sao, sẽ có thiên lôi thay ta dòm ngó nhà ngươi. 😈
                </div> -->
    </div>
  </div>
  <div class="footer">
    <p>Created with <i class="em em-coffee"></i> <a href="http://github.com/huytd/ristretto-rs">ristretto.rs</a></p>
    <div class="social">
      <a target="_blank" href="https://github.com/dntam00"><i class="icon-github-squared"></i></a>
      <a target="_blank" href="https://www.linkedin.com/in/dang-ngoc-tam/"><i class="icon-linkedin-squared"></i></a>
    </div>
  </div>
  <script type="text/javascript" async=""
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            skipTags: ["script","noscript","style","textarea", "code"],
            ignoreClass: ["comment", "comment-list"]
          }
        });
  </script>
</body>

</html>